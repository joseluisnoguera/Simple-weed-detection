{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosas para procesamiento de imágenes:\n",
    "* Evaluar características de la cámara\n",
    "* Normalización (ver si los índices normalizan o estudiar si la normalización rompe el índice)\n",
    "* Medir más características en el final, para discriminar de otra manera, ej: índice de textura\n",
    "\n",
    "Informe breve que describa las acciones realizadas para todas las etapas, decisiones en cada una, resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "Indices seleccionados:\n",
    "* Cloudy days: CIVE\n",
    "* Sunny days: ExG\n",
    "\n",
    "Las partes quemadas de la imagen afectan en los índices (es algo esperado).<br>\n",
    "Hay que probar las otras configuraciones de la cámara para detectar si las imágenes se queman.<br><br>\n",
    "Conocimiento previo para el algoritmo:\n",
    "* Cantidad de lineas en la imagen\n",
    "* Estadio del cultivo para estimar ancho de cada linea\n",
    "<br>\n",
    "\n",
    "#### Aprendido\n",
    "* Equalización de V en HSV rompe índices de vegetación (al menos los que trabajan con RGB)\n",
    "\n",
    "#### Notas\n",
    "* Cuando se haga el port, las imágenes binarizadas (uint8) cambiarlas a estructuras de Boolean\n",
    "* Para la detección de las rectas es bueno tener un microROI angosto (respecto al ancho del surco), para la máscara posterior es bueno agrandar su ancho real para solventar el problema de las hojas en el entre surco\n",
    "* MUY IMPORTANTE el ancho de surco (¿Para abajo o para arriba?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clases de archivos de test:\n",
    "* Imagenes mal clasificadas en la última corrida: {1,2,7,8,9,10,11,14,17,20,21,22,26,29,30,31,32}\n",
    "\n",
    "Problemas:\n",
    "* Detección de lagunas de maleza\n",
    "* Ángulos no posibles en rectas\n",
    "* Área de maleza extendida por fuera de los márgenes\n",
    "* No detecta picos en el borde de los histogramas\n",
    "* Agregar sentencias de control para descartar imágenes con detección erronea (rectas que se intersecan en la imagen)\n",
    "\n",
    "Algunas de las imágenes mal clasificadas se deben descartar.<br>\n",
    "Para la próxima hay que guardar la información de ángulo de toma, ancho de cultivo y altura. Se debe armar un esqueleto que permita mantener estos durante la toma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.157637Z",
     "start_time": "2020-02-14T00:52:47.292117Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns # Para graficar boxplots\n",
    "from ipynb.fs.full.Utils import *\n",
    "from mpl_toolkits.mplot3d import axes3d # Para realizar gráficas 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.170630Z",
     "start_time": "2020-02-14T00:52:48.160627Z"
    }
   },
   "outputs": [],
   "source": [
    "reduction_to_see = 0.6 # Reducción del tamaño original para poder ver las imágenes en tamañas chicas\n",
    "crop_width_bottom = 60 # Ancho de línea de cultivo en píxeles\n",
    "crop_width_top = 15\n",
    "rs_ratio = 0.25  # un cuarto de la imagen original\n",
    "addition = 0.4  # Este porcentaje de ancho es dependiente del tipo de cultivo y el estadío en el que se encuentra\n",
    "\n",
    "list_to_invert = {'exg', 'exgr', 'veg', 'com1', 'com2'}\n",
    "\n",
    "kernel_ones = np.ones((3,3), np.uint8)\n",
    "kernel_edge = np.array([[3, 0, -3],  # Segmentos verticales\n",
    "                        [10, 0, -10],\n",
    "                        [3, 0, -3]])\n",
    "# kernel_edge2 = np.array([[1, 0, -1],  # Segmentos verticales\n",
    "#                         [2, 0, -2],\n",
    "#                         [1, 0, -1]])\n",
    "kernel_vertical = np.array([\n",
    "    [0, 1, 0],\n",
    "    [0, 2, 0],\n",
    "    [0, 1, 0]\n",
    "], np.uint8)\n",
    "kernel_horizontal = np.array([\n",
    "    [0, 0, 0],\n",
    "    [1, 1, 1],\n",
    "    [0, 0, 0]\n",
    "], np.uint8)\n",
    "kernel_diagonal_1 = np.array([\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 0]\n",
    "], np.uint8)\n",
    "kernel_diagonal_2 = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]\n",
    "], np.uint8)\n",
    "kernel_cruz = np.array([\n",
    "    [0, 1, 0],\n",
    "    [1, 1, 1],\n",
    "    [0, 1, 0]\n",
    "], np.uint8)\n",
    "kernel_x = np.array([\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 1]\n",
    "], np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recorte de ROI (80% inferior de la imagen para eliminar ruido generado en el punto de fuga)\n",
    "* Calculo con índice CIVE\n",
    "* Segmentación dinámica meidante el método de Otsu\n",
    "* Reducción a un cuarto del tamaño original\n",
    "* Obtención de porcentaje de vegetación en imágen\n",
    "* Eroción sí el porcentaje de vegetación es mayor a 12%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.337319Z",
     "start_time": "2020-02-14T00:52:48.172672Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "path_to_imgs = 'img/test/'\n",
    "#1,2,7,8,9,10,11,14,17,20,21,22,26,29,30,31,32\n",
    "file_name = 'test10'\n",
    "_original = cv2.imread(path_to_imgs + file_name + '.png', cv2.IMREAD_COLOR)\n",
    "if _original is None:\n",
    "    print('Warning: imagen no cargada')\n",
    "# else:\n",
    "# original, file_name = take_random_picture(path_to_imgs, 'test', 'jpg')\n",
    "#     mostrar_img(file_name,_original, reduction_to_see)\n",
    "# Se hicieron pruebas con test4 o test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.341251Z",
     "start_time": "2020-02-14T00:52:48.338259Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cortar la parte superior de la imagen (esto se calcula de manera manual, depende del ángulo de pitch que tenga la cámara)\n",
    "\n",
    "original = v_crop_top(_original, 0.25)\n",
    "# mostrar_img(file_name,original, reduction_to_see)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.598530Z",
     "start_time": "2020-02-14T00:52:48.343241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Índices posibles: cive exr veg exg exgr com1 com2\n",
    "\n",
    "indice_seleccionado = 'exg'\n",
    "index_img = img_to_color_index(original, indice_seleccionado)\n",
    "# mostrar_img(file_name,index_img, reduction_to_see)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.664026Z",
     "start_time": "2020-02-14T00:52:48.599548Z"
    }
   },
   "outputs": [],
   "source": [
    "# La convierto en binario de 8 bits para aplicar Otsu\n",
    "gray_ind_img = scaling(index_img, 255)\n",
    "if (indice_seleccionado in list_to_invert):\n",
    "    gray_ind_img = cv2.bitwise_not(gray_ind_img)\n",
    "ret, segmented = cv2.threshold(\n",
    "    gray_ind_img, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "# mostrar_imgs([file_name, indice_seleccionado + 'with otsu'],[original, segmented], reduction_to_see)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ indice_seleccionado +'.png', segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.691913Z",
     "start_time": "2020-02-14T00:52:48.665009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utilizar el algoritmo con un reescalado de la imagen\n",
    "\n",
    "reducted = cv2.resize(segmented, None, fx=rs_ratio,\n",
    "                      fy=rs_ratio, interpolation=cv2.INTER_AREA)\n",
    "# mostrar_img('red', reducted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.702876Z",
     "start_time": "2020-02-14T00:52:48.695897Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de vegetación original: 0.2535546875\n",
      "Cantidad de vegetación reducido: 0.14337673611111112\n"
     ]
    }
   ],
   "source": [
    "# Apertura/eroción para eliminación de píxeles espurios o exceso de vegetación, denotando más las lineas\n",
    "# Utilizo solo eroción para acentuar la diferencia entre líneas de cultivo\n",
    "v_a = get_total_vegetation(reducted)\n",
    "print('Cantidad de vegetación original: ' + str(v_a))\n",
    "if (v_a > 0.15):\n",
    "    eroded = (cv2.erode(reducted, kernel_vertical))\n",
    "    v_a = get_total_vegetation(eroded)\n",
    "    print('Cantidad de vegetación reducido: ' + str(v_a))\n",
    "#     mostrar_imgs([file_name,'op1'], [reducted, eroded])\n",
    "else:\n",
    "    eroded = reducted.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.709875Z",
     "start_time": "2020-02-14T00:52:48.704872Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apertura para eliminar ruido\n",
    "\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "segmented_1 = cv2.morphologyEx(eroded, cv2.MORPH_OPEN, kernel_ones, iterations=1)\n",
    "morph = cv2.morphologyEx(segmented_1, cv2.MORPH_CLOSE, kernel_ones, iterations=1)\n",
    "# mostrar_imgs([file_name,'op1'], [eroded, morph])\n",
    "# diff = cv2.absdiff(segmented_1,segmented_2)\n",
    "# mostrar_imgs(['segmentada 1', 'segmentada 2', 'diferencia'], [segmented_1, segmented_2, diff], reduction_to_see)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.717871Z",
     "start_time": "2020-02-14T00:52:48.713851Z"
    },
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# ---------------------- Para implementar\n",
    "# Si se detectan lagunas de vegetación (tiene que ver con el ancho de los cultivos según la distancia en la imágen)\n",
    "# se debe marcar como zona con maleza, y el resto \"limpio\", ya que el algoritmo para detección de las rectas\n",
    "# no va a funcionar si siguieramos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptores de línea de cultivo\n",
    "* Histograma de la primera 12va franja horizontal de la imagen\n",
    "* Calculo de líneas descriptoras mediante Transformada de Hough con restricciónes<br>\n",
    "* Se generan grupos según las rectas que pase por +- crop_width/4 píxeles de cada punto de inicio\n",
    "* Se selecciona una recta de cada grupo que sea la que mayor cantidad de vegación cruce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.723855Z",
     "start_time": "2020-02-14T00:52:48.719833Z"
    }
   },
   "outputs": [],
   "source": [
    "# Segmento que es analizado con los histogramas\n",
    "# img_temp = morph[morph.shape[0] - h_space:morph.shape[0], 0:morph.shape[1]]\n",
    "# mostrar_img('segmento bajo', img_temp)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_' + 'segmentos' +'.png', img_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.742773Z",
     "start_time": "2020-02-14T00:52:48.725815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146 293 458 588]\n"
     ]
    }
   ],
   "source": [
    "# Calcular histograma de la franja inferior de la imágen, detectar la cantidad de picos según la cantidad\n",
    "# de lineas se busquen, si hay más o menos de lo buscado se descarta la imagen.\n",
    "# Luego de calculados los picos, calcular su centroide (la media de la distribución alrededor del pico)\n",
    "\n",
    "# segment = seg_and[offset_seg_height:offset_seg_height + seg_height, 0:td_w]\n",
    "h_space = int(morph.shape[0]/12)\n",
    "indexes = get_maximum_points(reducted[morph.shape[0] - h_space:morph.shape[0], 0:morph.shape[1]], crop_width_bottom)\n",
    "print(indexes)\n",
    "#-------\n",
    "# horizontal_segment = reducted[morph.shape[0] - h_space:morph.shape[0], 0:morph.shape[1]]\n",
    "# histogram = column_histogram(horizontal_segment)\n",
    "\n",
    "# Dibujar linea para mostrar sector analizado, y guarda\n",
    "# _morph_aux1 = cv2.merge((morph, morph, morph))\n",
    "# _morph_aux1 = cv2.line(_morph_aux1, (0, morph.shape[0]-h_space),\n",
    "#                   (morph.shape[1], morph.shape[0]-h_space), (0, 0, 255), 1)\n",
    "# mostrar_img('line', _morph_aux1)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'segmentToInitialPoints' +'.png', _morph_aux1)\n",
    "# --------\n",
    "# x = np.arange(0, morph.shape[1], 1)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, histogram)\n",
    "# ax.set(xlabel='Columna', ylabel='Cantidad de vegetación', title='Histograma de vegetación')\n",
    "# ax.grid()\n",
    "# fig.savefig('img/test/histogram_vegetation.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.749785Z",
     "start_time": "2020-02-14T00:52:48.745762Z"
    }
   },
   "outputs": [],
   "source": [
    "# El tamaño de ventana depende del ancho de las lineas, se busca un valor de manera que suavice y resalte los picos de cultivo\n",
    "# El grado del polinomio (por prueba) resulto ser mejor con grado 1, y eso puede ayudar en los calculos\n",
    "# Buscar como implementarlo en c++ (Savitzky Golay filter)\n",
    "\n",
    "# Sumo uno al ancho para que sea impar, resto 10 para mayor resolución\n",
    "#-----\n",
    "# window_length = int(crop_width*0.4)\n",
    "# window_length = window_length+1 if (window_length%2==0) else window_length\n",
    "# smoothed_2dg = (savgol_filter(histogram, window_length=window_length,\n",
    "#                               polyorder=1)).astype(np.int16)\n",
    "\n",
    "#------- Manual\n",
    "# winSize = crop_width_bottom\n",
    "# winMidSize = int(winSize/2)\n",
    "# smoothed = np.zeros(histogram.shape, np.int16)\n",
    "# for i in range(0,len(histogram)):\n",
    "#     total = 0\n",
    "#     for j in range(0,winSize):\n",
    "#         tmp = i - winMidSize + j\n",
    "#         if (tmp >= 0 and  tmp < len(histogram)):\n",
    "#             total += histogram[tmp]\n",
    "#     smoothed[i] = int(total/winSize)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, smoothed)\n",
    "# ax.set(xlabel='Columna', ylabel='Cantidad de vegetación',\n",
    "#        title='Histograma de vegetación suavizado')\n",
    "# ax.grid()\n",
    "# fig.savefig('img/test/histogram_vegetation_smoothed.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.755768Z",
     "start_time": "2020-02-14T00:52:48.750786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Detección de picos, basados en una ventana de desplazamiento y punto de inflexión\n",
    "# Los interpola\n",
    "\n",
    "# indexes = peakutils.indexes(\n",
    "#     smoothed, thres=0.05/max(smoothed_2dg), min_dist=crop_width_bottom*1.8)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, smoothed)\n",
    "# ax.scatter(indexes, smoothed[indexes], c='blue')\n",
    "# ax.set(xlabel='Columna', ylabel='Cantidad de vegetación', title='Máximos locales')\n",
    "\n",
    "#------------\n",
    "# histogram = histogram.astype(np.int16)\n",
    "# indexes = peakutils.indexes(\n",
    "#     histogram, thres=0.05/max(histogram), min_dist=crop_width_bottom*1.8)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, histogram)\n",
    "# ax.scatter(indexes, histogram[indexes], c='blue')\n",
    "# ax.set(xlabel='Columna', ylabel='Cantidad de vegetación', title='Máximos locales')\n",
    "# fig.savefig('img/test/histogram_vegetation_smoothed+peaks.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.762719Z",
     "start_time": "2020-02-14T00:52:48.756764Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dibujar linea para mostrar sector analizado, y guarda\n",
    "\n",
    "# _morph_aux1 = cv2.merge((morph, morph, morph))\n",
    "# _morph_aux1 = cv2.line(_morph_aux1, (0, middle),\n",
    "#                   (morph.shape[1], middle), (0, 0, 255), 1)\n",
    "# for i in range(0, len(indexes)):\n",
    "#     _morph_aux1 = cv2.line(\n",
    "#         _morph_aux1, (indexes[i], 0), (indexes[i], morph.shape[0]), (255, 0, 0), 2)\n",
    "#     _morph_aux1 = cv2.line(\n",
    "#         _morph_aux1, (upper_limit[i], 0), (upper_limit[i], morph.shape[0]), (255, 255, 0), 2)\n",
    "#     _morph_aux1 = cv2.line(\n",
    "#         _morph_aux1, (lower_limit[i], 0), (lower_limit[i], morph.shape[0]), (255, 255, 0), 2)\n",
    "# _morph_aux1 = _morph_aux1[_morph_aux1.shape[0] - h_space:_morph_aux1.shape[0], 0:_morph_aux1.shape[1]]\n",
    "# mostrar_img('line', _morph_aux1)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'segmentToHough' +'.png', _morph_aux1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:48.771695Z",
     "start_time": "2020-02-14T00:52:48.765713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se calculan las rectas de Hough que salen de los puntos iniciales, que cumplan con las condiciones de ángulo\n",
    "# verificar que otras condiciones hay\n",
    "\n",
    "middle = eroded.shape[0]-int(eroded.shape[0]/2)\n",
    "bottom_image = morph[middle:eroded.shape[0], 0:eroded.shape[1]]\n",
    "# mostrar_img('bottom', bottom_image)\n",
    "edges = cv2.filter2D(bottom_image, -1, kernel_edge)\n",
    "# edges2 = cv2.filter2D(bottom_image, -1, kernel_edge2)\n",
    "# mostrar_img('edges conv 1', edges)\n",
    "# mostrar_imgs(['edges conv 1', 'edges conv 2'], [edges,edges2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:51.547795Z",
     "start_time": "2020-02-14T00:52:48.773688Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%timeit -n 10 -r 10\n",
    "# 19.3 ms ± 525 µs\n",
    "# Busqueda de líneas con Hough\n",
    "\n",
    "lines = cv2.HoughLines(edges, 18, np.pi/180, 800)\n",
    "\n",
    "third_1 = (int)(bottom_image.shape[1]/3)\n",
    "third_2 = (int)(bottom_image.shape[1]*(2/3))\n",
    "delta = int(crop_width_bottom/2)\n",
    "upper_limit = indexes + delta\n",
    "lower_limit = indexes - delta\n",
    "groups = {}\n",
    "if type(lines) is np.ndarray:\n",
    "    for line in lines:\n",
    "        for rho, theta in line:\n",
    "            if (np.sin(theta) != 0):\n",
    "                m = -(np.cos(theta)/np.sin(theta))\n",
    "                b = rho/np.sin(theta)\n",
    "                x = int((bottom_image.shape[0]-b)/m)\n",
    "                initial_points_condition = False\n",
    "                group = -1\n",
    "                for i in range(0, len(indexes)):\n",
    "                    if (x <= upper_limit[i] and x >= lower_limit[i]):\n",
    "                        group = i\n",
    "                # Ángulos de control configurables\n",
    "                correct_angle_and_position = (x < third_1 and theta < 0.49 and theta > 0.2) or \\\n",
    "                    (x > third_2 and theta < 2.92 and theta > 2.65) or \\\n",
    "                    (x > third_1 and x < third_2 and (theta < 0.39 or theta > 2.75))\n",
    "#                 correct_angle_and_position = True\n",
    "                if (x > 0 and x < bottom_image.shape[1] and group != -1 and correct_angle_and_position):\n",
    "                    line = Line(m,b)\n",
    "                    line.set_white_amount(bottom_image)\n",
    "                    if group not in groups.keys():\n",
    "                        groups[group] = line\n",
    "                    else:\n",
    "                        if (groups[group].white_amount < line.white_amount):\n",
    "                            groups[group] = line\n",
    "                            \n",
    "#Si Houghs no detecta rectas que se ajuste a alguno de los grupos, estos quedan vacíos y dan KeyError\n",
    "# Para ver las rectas obtenidas por TH\n",
    "# with_lines = cv2.merge((bottom_image, bottom_image, bottom_image))\n",
    "# for key in groups.keys():\n",
    "#     line = groups.get(key)\n",
    "#     m = line.m\n",
    "#     b = line.b\n",
    "#     y0 = 0\n",
    "#     x0 = line.get_x(y0)\n",
    "#     y1 = with_lines.shape[0]\n",
    "#     x1 = line.get_x(y1)\n",
    "#     cv2.line(with_lines, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "\n",
    "# mostrar_img('Lines with hough', with_lines)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'lines' +'.png', with_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de centroides\n",
    "* Se utilizan doce segmentos, que se distribuyen cuatro en mitad baja y ocho en la parte alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:51.566745Z",
     "start_time": "2020-02-14T00:52:51.549789Z"
    }
   },
   "outputs": [],
   "source": [
    "# Segmentación de la imagen en partes que disminuyen un 5% cuando se avanza hacia arriba\n",
    "\n",
    "divisions = cv2.merge((morph, morph, morph))\n",
    "total_y = morph.shape[0]\n",
    "y_segments_bottom = np.arange(11,15) # Para obtener los 4 segmentos inferiores\n",
    "y_segments_top = np.arange(0,9) # Para obtener los 8 segmentos superiores\n",
    "# Botto: [384, middle], Top: [middle, 0]\n",
    "y_segments_bottom = (np.multiply((np.true_divide(y_segments_bottom, np.sum(y_segments_bottom))), middle)).astype(np.uint16)\n",
    "y_segments_top = (np.multiply((np.true_divide(y_segments_top, np.sum(y_segments_top))), middle)).astype(np.uint16)\n",
    "y_segments_bottom = y_segments_bottom[::-1]\n",
    "y_segments_top = y_segments_top[::-1]\n",
    "y_segments_bottom[0] = y_segments_bottom[0] + middle - np.sum(y_segments_bottom)\n",
    "y_segments_top[0] = y_segments_top[0] + middle - np.sum(y_segments_top)\n",
    "y_segments = np.concatenate((y_segments_bottom[0:len(y_segments_bottom) - 1], y_segments_top[0:len(y_segments_top)]))\n",
    "for i in range(len(y_segments) - 2, -1, -1):\n",
    "    y_segments[i] = y_segments[i] + y_segments[i+1]\n",
    "y_segments = np.concatenate(([morph.shape[0]], y_segments))\n",
    "\n",
    "# Para graficar\n",
    "# for y in y_segments:\n",
    "#     if y > 0:\n",
    "#         if (y >= middle):\n",
    "#             cv2.line(divisions, (0, y),\n",
    "#                      (morph.shape[1], y), (255, 0, 0), 1)\n",
    "#         else:\n",
    "#             cv2.line(divisions, (0, y),\n",
    "#                      (morph.shape[1], y), (0, 255, 0), 1)\n",
    "\n",
    "# print('Una cantidad de ' + str(len(y_segments) - 1) + ' segmentos')\n",
    "# print(y_segments)\n",
    "# mostrar_img('segments', divisions)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'segmentos' +'.png', divisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:51.649604Z",
     "start_time": "2020-02-14T00:52:51.568741Z"
    }
   },
   "outputs": [],
   "source": [
    "# Para ver la primera franja con los segmentos de valores de cada línea de cultivo\n",
    "\n",
    "# bottom_segment = morph[y_segments[1]:y_segments[0],:]\n",
    "# bottom_segment = cv2.merge((bottom_segment, bottom_segment, bottom_segment))\n",
    "# mostrar_img('bottom', bottom_segment)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'parte_baja' +'.png', bottom_segment)\n",
    "# down_ind = indexes - int(crop_width_bottom / 2)\n",
    "# up_ind = indexes + int(crop_width_bottom / 2)\n",
    "# for i in range(0, len(indexes)):\n",
    "#     cv2.line(bottom_segment, (down_ind[i], 0),\n",
    "#                      (down_ind[i], bottom_image.shape[0]), (255, 255, 55), 2)\n",
    "#     cv2.line(bottom_segment, (up_ind[i], 0),\n",
    "#                      (up_ind[i], bottom_image.shape[0]), (255, 255, 55), 2)\n",
    "#     cv2.line(bottom_segment, (indexes[i], 0),\n",
    "#                      (indexes[i], bottom_image.shape[0]), (255, 0, 0), 2)\n",
    "# mostrar_img('abc', bottom_segment)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'parte_baja_con_sectores' +'.png', bottom_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:51.655589Z",
     "start_time": "2020-02-14T00:52:51.650579Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dibujo de líneas para corroborar con los centroides que se calculan posteriormente\n",
    "\n",
    "# divisions_aux1 = divisions.copy()\n",
    "# img_offset = middle\n",
    "# for key in groups.keys():\n",
    "#     line = groups.get(key)\n",
    "#     m = line.m\n",
    "#     b = line.b + img_offset\n",
    "#     y0 = img_offset\n",
    "#     x0 = int((y0-b)/m)\n",
    "#     y1 = divisions_aux1.shape[0]\n",
    "#     x1 = int((y1-b)/m)\n",
    "#     cv2.line(divisions_aux1, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "# mostrar_img('lineas', divisions_aux1)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'segmentos_con_TH' +'.png', divisions_aux1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:52:51.662551Z",
     "start_time": "2020-02-14T00:52:51.656563Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ya que la recta está calculada para la parte inferior, es necesario un offset de b para transladarla\n",
    "img_offset = middle\n",
    "for key in groups.keys():\n",
    "    line = groups.get(key)\n",
    "    line.b = line.b + img_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo de los centroides de la parte inferior de la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:01:11.607147Z",
     "start_time": "2020-02-14T01:01:10.052707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se calcula el centro del ROI en base a las rectas encontradas por TH\n",
    "# Si el microROI no tiene píxeles blancos se asume que el centro es el centroide\n",
    "# Tres vacios consecutivos en una línea es el tope, sino se descarta la imagen <----------------------- a implementar (se puede realizar con un assertion)\n",
    "\n",
    "# Si se dibujan las rectas para corroborar centroides, comentar estas líneas\n",
    "divisions_aux1 = divisions.copy()\n",
    "\n",
    "x_centroids_matrix = np.zeros((len(indexes), len(y_segments) - 1), np.uint16)\n",
    "y_centroids_matrix = np.zeros((len(indexes), len(y_segments) - 1), np.uint16)\n",
    "crop_width_aux = crop_width_bottom\n",
    "width_decay = (crop_width_aux - crop_width_top) / (len(y_segments) - 1)  # (inicial-final)/pasos\n",
    "\n",
    "segment_index = 1\n",
    "while y_segments[segment_index] >= middle:\n",
    "    for key in groups.keys():\n",
    "        # Obtener cada descriptor de línea\n",
    "        line = groups.get(key)\n",
    "        y1, y2 = y_segments[segment_index - 1], y_segments[segment_index]  # Inferior, superior\n",
    "        # El x del inferior, respecto a la recta\n",
    "        x_temp = line.get_x(y1)\n",
    "        # Desplazamientos según ancho de línea\n",
    "        x1, x2 = x_temp - int(crop_width_aux/2), x_temp + int(crop_width_aux/2)\n",
    "        if (x1 < 0): x1 = 0\n",
    "        if (x2 > morph.shape[1]-1): x2 = morph.shape[1]-1\n",
    "        # Pasarle microimagen con desplazamiento en x e y\n",
    "        centroid = MicroROI(morph[y2:y1, x1:x2], x1, y2)\n",
    "        x_centroids_matrix[key, segment_index - 1], y_centroids_matrix[key,\n",
    "                                                                       segment_index - 1] = centroid.get_centroid()\n",
    "        # Dibujar el centroide y la micro ROI\n",
    "        cv2.line(divisions_aux1, (x1, y1), (x1, y2), (255, 255, 0), 1)\n",
    "        cv2.line(divisions_aux1, (x2, y1), (x2, y2), (255, 255, 0), 1)\n",
    "        cv2.circle(\n",
    "            divisions_aux1, (x_centroids_matrix[key, segment_index - 1], y_centroids_matrix[key, segment_index - 1]), 3, (255, 0, 255), 2)\n",
    "        key = key + 1  # Próxima línea\n",
    "    # Nuevo ancho de microROI\n",
    "    crop_width_aux = crop_width_aux - width_decay\n",
    "    segment_index = segment_index + 1  # Próxima franja\n",
    "\n",
    "mostrar_img('divisiones y centroides', divisions_aux1)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'centroides' +'.png', divisions_aux1)\n",
    "# print('pos x')\n",
    "# print(x_centroids_matrix)\n",
    "# print('pos y')\n",
    "# print(y_centroids_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(crop_width_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo de los centroides de la parte superior de la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:16:48.297647Z",
     "start_time": "2020-02-14T01:16:40.264706Z"
    },
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:-5.079812206572538 b:1131 x_offset0 white amount:-1\n",
      "m:-13.306122448982551 b:4165 x_offset0 white amount:-1\n",
      "m:2.982154958211601 b:-1028 x_offset0 white amount:-1\n",
      "m:1.967795210569598 b:-829 x_offset0 white amount:-1\n",
      "m:-4.517538815411268 b:1022 x_offset0 white amount:-1\n",
      "m:-12.57894736842745 b:3907 x_offset0 white amount:-1\n",
      "m:3.3911483253593047 b:-1198 x_offset0 white amount:-1\n",
      "m:1.9204514175611893 b:-822 x_offset0 white amount:-1\n",
      "m:-4.8767222625095465 b:1092 x_offset0 white amount:-1\n",
      "m:-0.1999999999997158 b:174 x_offset0 white amount:-1\n",
      "m:3.741407528641867 b:-1336 x_offset0 white amount:-1\n",
      "m:1.9491704906459426 b:-842 x_offset0 white amount:-1\n",
      "m:-4.936363636363655 b:1104 x_offset0 white amount:-1\n",
      "m:-0.9894453848451412 b:446 x_offset0 white amount:-1\n",
      "m:3.7529291900155974 b:-1350 x_offset0 white amount:-1\n",
      "m:2.3052308871432667 b:-1007 x_offset0 white amount:-1\n",
      "m:-4.370468611847834 b:995 x_offset0 white amount:-1\n",
      "m:-0.9128045235956176 b:397 x_offset0 white amount:-1\n",
      "m:4.069230769230993 b:-1467 x_offset0 white amount:-1\n",
      "m:1.868106371586681 b:-797 x_offset0 white amount:-1\n",
      "m:-3.991692627206076 b:915 x_offset0 white amount:-1\n",
      "m:-0.7976237623762472 b:339 x_offset0 white amount:-1\n",
      "m:4.040000000000336 b:-1454 x_offset0 white amount:-1\n",
      "m:1.728020364205656 b:-733 x_offset0 white amount:-1\n",
      "m:-4.090361445783027 b:929 x_offset0 white amount:-1\n",
      "m:-2.4244306418213317 b:954 x_offset0 white amount:-1\n",
      "m:3.4556962025328937 b:-1235 x_offset0 white amount:-1\n",
      "m:1.7843740387571767 b:-759 x_offset0 white amount:-1\n",
      "m:-4.400651465798727 b:1003 x_offset0 white amount:-1\n",
      "m:-2.9360967184835873 b:1146 x_offset0 white amount:-1\n",
      "m:2.4279279279289065 b:-852 x_offset0 white amount:-1\n",
      "m:1.7402826855118438 b:-737 x_offset0 white amount:-1\n"
     ]
    }
   ],
   "source": [
    "# En y llevo el nivel actual, calculos la recta de cada línea con los últimos cuatro centroides\n",
    "# Usar la recta con los últimos cuatro elementos para el ROI del siguiente nivel\n",
    "# Calcula centroides del siguiente nivel y agregarlos en las matrices correspondientes\n",
    "divisions_aux2 = divisions_aux1.copy()\n",
    "# Continuo con el y de la celda anterior, para continuar con los segmentos correspondientes\n",
    "last_centroids_index = 0\n",
    "segment_index_aux = segment_index\n",
    "crop_width_aux2 = crop_width_aux\n",
    "while segment_index_aux != (len(y_segments)):\n",
    "    for line_index in range(0, x_centroids_matrix.shape[0]):  # Para cada línea\n",
    "        # Tomo elementos de [i, i+3] correspondientes a los últimos cuatro centroides\n",
    "        x_list = x_centroids_matrix[line_index, last_centroids_index:last_centroids_index + 4]\n",
    "        y_list = y_centroids_matrix[line_index, last_centroids_index:last_centroids_index + 4]\n",
    "        last_centroid = (x_centroids_matrix[line_index, last_centroids_index+3], y_centroids_matrix[line_index, last_centroids_index+3])\n",
    "        m, b = least_squares_line(x_list, y_list, last_centroid)\n",
    "        if (m < 80):\n",
    "            line = Line(m,b)\n",
    "        else:\n",
    "            line = Line(m,x_offset=mean(x_list))\n",
    "        y1, y2 = y_segments[segment_index_aux-1], y_segments[segment_index_aux]  # Inferior, superior\n",
    "#         x1, x2 = line.get_x(divisions_aux2.shape[0]), line.get_x(y2)\n",
    "#         cv2.line(divisions_aux2,\n",
    "#                  (x1, divisions_aux2.shape[0]), (x2, y2), (0, 0, 255), 2)\n",
    "        x_temp = line.get_x(y1)\n",
    "#         x_estimated = line.get_x((y2-y1)/2 + y1)\n",
    "        # Desplazamientos según ancho de línea\n",
    "        x1, x2 = x_temp - int(crop_width_aux2 / 2), x_temp + int(crop_width_aux2 / 2)\n",
    "        # Pasarle microimagen con desplazamiento en x e y\n",
    "        temp = morph[y2:y1, x1:x2]\n",
    "        centroid = MicroROI(temp, x1, y2)\n",
    "        x_centroids_matrix[line_index, segment_index_aux-1], y_centroids_matrix[line_index, segment_index_aux-1] = centroid.get_centroid()\n",
    "        # Dibujar el centroide y la micro ROI\n",
    "#         if (line_index == 1):\n",
    "        cv2.line(divisions_aux2, (x1, y1), (x1, y2), (255, 255, 0), 1)\n",
    "        cv2.line(divisions_aux2, (x2, y1), (x2, y2), (255, 255, 0), 1)\n",
    "        cv2.circle(divisions_aux2, (x_centroids_matrix[line_index, segment_index_aux-1], y_centroids_matrix[line_index, segment_index_aux-1]), 3, (255, 0, 255), 2)\n",
    "    segment_index_aux = segment_index_aux + 1  # Próxima franja\n",
    "    crop_width_aux2 = crop_width_aux2 - width_decay\n",
    "    last_centroids_index = last_centroids_index + 1\n",
    "\n",
    "# print('x')\n",
    "# print(x_centroids_matrix)\n",
    "# print('y')\n",
    "# print(y_centroids_matrix)\n",
    "mostrar_img('centroides', divisions_aux2)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'centroides_hasta_arriba' +'.png', divisions_aux2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilización de ajuste por mínimos cuadrados\n",
    "* Cálculo de coeficientes de recta: mx+b\n",
    "* Cálculo de coeficientes de cuadrática: ax^2+bx+c (Implementado, pero no se utiliza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:07:06.257794Z",
     "start_time": "2020-02-14T01:07:05.616915Z"
    }
   },
   "outputs": [],
   "source": [
    "# Una vez obtenidos todos los centroides de cada línea se realiza una análisis\n",
    "# de regresión (se puede aplicar a cada conjunto de centroides y obtener los\n",
    "# descriptores de la curva que mejor se adapte)\n",
    "# Utiliza nuevamente mínimos cuadrados, y el calculo del resto para quedarse\n",
    "# con la que mejor se ajuste (recta o cuadrática), se puede detectar la mejor por acumulación de vegetación\n",
    "divisions_aux3 = divisions_aux2.copy()\n",
    "y1, y2 = 0, divisions_aux3.shape[0]\n",
    "y = np.arange(y1, y2)\n",
    "# v_amount_line = 0\n",
    "\n",
    "\n",
    "lines = {}\n",
    "# Independiente, líneal y cuadrático por línea\n",
    "# quadratic_coef = np.zeros([x_centroids_matrix.shape[0], 3], np.float16)\n",
    "\n",
    "for line_index in range(0, x_centroids_matrix.shape[0]):  # Para cada línea\n",
    "    x_list = x_centroids_matrix[line_index, 0:x_centroids_matrix.shape[1]]\n",
    "    y_list = y_centroids_matrix[line_index, 0:y_centroids_matrix.shape[1]]\n",
    "\n",
    "    # Mínimos cuadrados para recta\n",
    "    x_mean = int(mean(x_list))\n",
    "    y_mean = int(mean(y_list))\n",
    "    \n",
    "    m,b = least_squares_line(y_list, x_list, (y_mean, x_mean))\n",
    "    m = 1/m\n",
    "    if (m < 80):\n",
    "        b = - b * m\n",
    "        lines[line_index] = Line(m,b)\n",
    "    else:\n",
    "        lines[line_index] = Line(m,x_offset=x_mean)\n",
    "#     print(str(line_index)+' ',end='')\n",
    "#     print(' b:'+str(lines[line_index].b),end='')\n",
    "#     print(' m:'+str(lines[line_index].m),end='')\n",
    "#     print(' x_offset:'+str(lines[line_index].x_offset))\n",
    "    \n",
    "    x1, x2 = lines[line_index].get_x(y1), lines[line_index].get_x(y2)\n",
    "    \n",
    "    cv2.line(divisions_aux3, (x1, y1), (x2, y2), (155, 255, 69), 2)\n",
    "    \n",
    "#     lines[line_index].set_white_amount(morph)\n",
    "#     print(lines[line_index].white_amount)\n",
    "\n",
    "#     # Mínimos cuadrados para cuadrática\n",
    "#     quadratic_coef[line_index, 2], quadratic_coef[line_index,\n",
    "#                                                   1], quadratic_coef[line_index, 0] = least_squares_quadratic(x_list, y_list)\n",
    "#     x1_quadratic, x2_quadratic = get_x_in_quadratic(\n",
    "#         y, quadratic_coef[line_index, 2], quadratic_coef[line_index, 1], quadratic_coef[line_index, 0])\n",
    "    # Guardar los x ya que los calculé, para no recalcular luego\n",
    "#     x_quadratic = x1_quadratic if (\n",
    "#         0 < x1_quadratic[0] and x1_quadratic[0] < divisions_aux3.shape[1]) else x2_quadratic\n",
    "#     if (not np.isnan(x_quadratic).any()):\n",
    "#         v_amount_quadratic = v_amount_quadratic + get_vegetation_in_quadratic(\n",
    "#             morph, quadratic_coef[line_index, 2], quadratic_coef[line_index, 1], quadratic_coef[line_index, 0], x_quadratic)\n",
    "# #         Agregar a imagen\n",
    "#         pts = np.zeros((x_quadratic.shape[0], 2), np.uint64)\n",
    "#         for i in range(0, x_quadratic.shape[0]):\n",
    "#             pts[i, 0] = x_quadratic[i]\n",
    "#             pts[i, 1] = y[i]\n",
    "#         cv2.polylines(divisions_aux3, [pts], False, (0, 0, 255), 2)\n",
    "\n",
    "# print(x_centroids_matrix[1,::])\n",
    "# print(y_centroids_matrix[1,::])\n",
    "# print(\"b: \" + str(lines[1,0]) + \" y m: \" + str(lines[1,1]))\n",
    "# print('Vegetación en línea: ' + str(v_amount_line))\n",
    "mostrar_img('total', divisions_aux3)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'cuadratica_minimos_cuadrados' +'.png', divisions_aux3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado de curvas\n",
    "* Ya que solo se trabaja con rectas, se pospone estos filtros para luego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:53:15.857931Z",
     "start_time": "2020-02-14T00:53:15.853948Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selección y verificación (reglas para verificar que sean rectas/cuadráticas\n",
    "#válidas)\n",
    "# 1) Regularidad en el espaciado entre líneas\n",
    "# 2) No intersección dentro del ROI ni extensión por debajo de la imagen\n",
    "\n",
    "\n",
    "\n",
    "#Salteo esta parte para luego, ya que las rectas encontradas con la imagen de prueba no tiene problemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de máscaras con el uso de curvas descriptoras\n",
    "* Actuamente solamente con rectas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:07:09.359181Z",
     "start_time": "2020-02-14T01:07:09.353232Z"
    }
   },
   "outputs": [],
   "source": [
    "# Máscaras según el ancho (90 píxeles a ojo, 20px arriba) de cultivo y de surco\n",
    "# Solo estoy tomando en cuenta la recta, haría falta cambiar esto para utilizar la recta o la cuadrática según corresponda\n",
    "\n",
    "crop_mask = np.zeros(\n",
    "    (divisions_aux3.shape[0], divisions_aux3.shape[1]), np.uint8)\n",
    "entre_surco_mask = crop_mask.copy()\n",
    "y1, y2 = 0, crop_mask.shape[0]\n",
    "\n",
    "crop_width_tmp = crop_width_bottom + crop_width_bottom * addition\n",
    "crop_width_t = crop_width_top + crop_width_top * addition\n",
    "crop_width_decay = (crop_width_tmp - crop_width_t) / y2\n",
    "\n",
    "#Debo cambiarlo por obtener el máximo de las distancias\n",
    "#Es necesario ordenar ya que las rectas pueden no estar en orden de izq a der\n",
    "furrow_width = int(get_max_distance(np.sort(indexes))) \n",
    "# Para calcular el promedio del espacio entre entre líneas en el tope\n",
    "indexes_top = np.zeros(indexes.shape)\n",
    "for line_index in range(0, len(lines)):\n",
    "    indexes_top[line_index] = lines[line_index].get_x(0)\n",
    "furrow_width_top = int(get_max_distance(np.sort(indexes_top))) \n",
    "furrow_width_decay = (furrow_width - furrow_width_top) / y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:53:15.947686Z",
     "start_time": "2020-02-14T00:53:15.942689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "m:-4.664679393670325 b:1054.2175429694935 x_offset0 white amount:-1\n",
      "1\n",
      "m:-2.9225427119287155 b:1107.6436878209831 x_offset0 white amount:-1\n",
      "2\n",
      "m:3.4403816044680235 b:-1217.8950879816803 x_offset0 white amount:-1\n",
      "3\n",
      "m:1.9723767911924521 b:-840.2325130479846 x_offset0 white amount:-1\n"
     ]
    }
   ],
   "source": [
    "for key in lines.keys():\n",
    "    print(key)\n",
    "    print(str(lines[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:43:28.932942Z",
     "start_time": "2020-02-14T00:43:17.219309Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creación de las máscaras sin superposición\n",
    "for y in range(y2 - 1, y1 - 1, -1):  # Desde la base a la parte superior de la imagen\n",
    "    tmp_crop_width = int(crop_width_tmp/2)\n",
    "    tmp_furrow_width = int(furrow_width/2)\n",
    "    for x in range(0, crop_mask.shape[1]):\n",
    "        result = is_crop_or_furrow_lineal(lines, (x, y), tmp_crop_width, tmp_furrow_width)\n",
    "        if (result == 1):\n",
    "            crop_mask[y, x] = 255\n",
    "        if (result == -1):\n",
    "            entre_surco_mask[y, x] = 255\n",
    "    crop_width_tmp = crop_width_tmp - crop_width_decay\n",
    "    furrow_width = furrow_width - furrow_width_decay\n",
    "\n",
    "mostrar_imgs(['máscara de cultivo', 'máscara de surco'],\n",
    "             [crop_mask, entre_surco_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:26:08.686511Z",
     "start_time": "2020-02-14T00:26:08.675884Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utilizar las máscaras, luego de escalarlas al tamaño original, con AND a la máscara de vegetación\n",
    "# _crop_mask = cv2.resize(crop_mask, None, fx=(1/rs_ratio),fy=(1/rs_ratio), interpolation=cv2.INTER_AREA)\n",
    "# entre_surco_mask = cv2.resize(entre_surco_mask, None, fx=(1/rs_ratio),fy=(1/rs_ratio), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'mascara_cultivo' +'.png', _crop_mask)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'mascara_surco' +'.png', entre_surco_mask)\n",
    "\n",
    "# _crop_mask = cv2.bitwise_and(_crop_mask, segmented)\n",
    "# entre_surco_mask = cv2.bitwise_and(entre_surco_mask, segmented)\n",
    "\n",
    "# Para la versión reducida\n",
    "crop_mask_aux1 = cv2.bitwise_and(crop_mask, reducted)\n",
    "furrow_crop_mask_aux1 = cv2.bitwise_and(entre_surco_mask, reducted)\n",
    "# mostrar_imgs(['máscara de cultivo', 'máscara de surco'],\n",
    "#              [crop_mask_aux1, furrow_crop_mask_aux1])\n",
    "\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'mascara_cultivo_veg' +'.png', crop_mask_aux1)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'mascara_surco_veg' +'.png', furrow_crop_mask_aux1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de distribución\n",
    "* Hace falta aislar píxeles de maleza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:26:08.770841Z",
     "start_time": "2020-02-14T00:26:08.692253Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preparación de datos para comparar distribución entre datos de crop y weed\n",
    "\n",
    "# x_v = []\n",
    "# y_v = []\n",
    "# z_v = []\n",
    "# x_w = []\n",
    "# y_w = []\n",
    "# z_w = []\n",
    "# v_data = []\n",
    "# w_data = []\n",
    "# v_i = 0\n",
    "# w_i = 0\n",
    "# tope = 300000\n",
    "# for x in range(0,segmented.shape[1]):\n",
    "#     for y in range(0, segmented.shape[0]):\n",
    "#         if (_crop_mask[y,x] == 255) and (v_i < tope):\n",
    "#             v_i = v_i + 1\n",
    "#             v_data.append(original[y,x])\n",
    "#             x, y, z = original[y,x]\n",
    "#             x_v.append(x)\n",
    "#             y_v.append(y)\n",
    "#             z_v.append(z)\n",
    "# #             v_data.append(original[y,x])\n",
    "#         if (_furrow_crop_mask[y,x] == 255) and (w_i < tope):\n",
    "#             w_i = w_i + 1\n",
    "#             w_data_data.append(original[y,x])\n",
    "#             x, y, z = original[y,x]\n",
    "#             x_w.append(x)\n",
    "#             y_w.append(y)\n",
    "#             z_w.append(z)\n",
    "# #             w_data.append(original[y,x])\n",
    "# x_v = np.array(x_v)\n",
    "# y_v = np.array(y_v)\n",
    "# z_v = np.array(z_v)\n",
    "# x_w = np.array(x_w)\n",
    "# y_w = np.array(y_w)\n",
    "# z_w = np.array(z_w)\n",
    "# v_data = np.array(v_data)\n",
    "# w_data = np.array(w_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:26:08.779019Z",
     "start_time": "2020-02-14T00:26:08.773760Z"
    }
   },
   "outputs": [],
   "source": [
    "# fix, ax = plt.subplots(1,2, sharey=True)\n",
    "# sns.boxplot(data=v_data, linewidth=2.5, palette='Set3', ax=ax[0])\n",
    "# sns.boxplot(data=w_data, linewidth=2.5, palette='Set1', ax=ax[1])\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(111, projection='3d')\n",
    "# ax1.scatter(x_v, y_v, z_v, c='g', marker='o')\n",
    "# ax1.scatter(x_w, y_w, z_w, c='r', marker='o')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación en cuadrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:26:09.793244Z",
     "start_time": "2020-02-14T00:26:08.781014Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tengo L: líneas y L+1: Surcos\n",
    "# Sabiendo el espaciado entre líneas, puedo calcular en que surco estoy\n",
    "# Tengo los índices de las franjas horizontales\n",
    "\n",
    "# Aplicar apertura o erosiones sobre la máscara de surco\n",
    "#kernel = np.ones((7,7),np.uint8)\n",
    "#apertura = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# _furrow_crop_mask_aperture = (cv2.erode(furrow_crop_mask_aux1, kernel))\n",
    "_furrow_crop_mask_aperture = cv2.morphologyEx(\n",
    "    furrow_crop_mask_aux1, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "# _furrow_crop_mask_aperture = cv2.morphologyEx(\n",
    "#     _furrow_crop_mask_aperture, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "# for i in range(0, 0):\n",
    "#     _furrow_crop_mask_aperture = cv2.morphologyEx(\n",
    "#         _furrow_crop_mask_aperture, cv2.MORPH_OPEN, kernel_vertical, iterations=1)\n",
    "#     _furrow_crop_mask_aperture = cv2.morphologyEx(\n",
    "#         _furrow_crop_mask_aperture, cv2.MORPH_OPEN, kernel_diagonal_1, iterations=1)\n",
    "#     _furrow_crop_mask_aperture = cv2.morphologyEx(\n",
    "#         _furrow_crop_mask_aperture, cv2.MORPH_OPEN, kernel_diagonal_2, iterations=1)\n",
    "#     _furrow_crop_mask_aperture = cv2.morphologyEx(\n",
    "#         _furrow_crop_mask_aperture, cv2.MORPH_OPEN, kernel_horizontal, iterations=1)\n",
    "tmp_red = cv2.resize(original, None, fx=rs_ratio*1.5,fy=rs_ratio*1.5, interpolation=cv2.INTER_AREA)\n",
    "mostrar_imgs(['orig', 'segment', 'apert'], [tmp_red ,furrow_crop_mask_aux1,\n",
    "                                 _furrow_crop_mask_aperture])\n",
    "\n",
    "# Gurdado para hacer comparativa\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'apertura1' +'.png', _furrow_crop_mask_aperture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:26:09.800814Z",
     "start_time": "2020-02-14T00:26:09.796236Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aplicar las máscaras de vegetación y de cultivo para clasificar visualmente\n",
    "# _crop_mask_aux = cv2.resize(crop_mask, None, fx=(1/rs_ratio),fy=(1/rs_ratio), interpolation=cv2.INTER_AREA)\n",
    "# _furrow_crop_mask_aux = cv2.resize(_furrow_crop_mask_aperture, None, fx=(1/rs_ratio),fy=(1/rs_ratio), interpolation=cv2.INTER_AREA)\n",
    "# zeros = np.zeros(_crop_mask_aux.shape, np.uint8)\n",
    "# mask = cv2.merge((zeros, _crop_mask_aux, _furrow_crop_mask_aux))\n",
    "# total = cv2.add(original, mask)\n",
    "# mostrar_imgs(['original', 'clasificada'], [original, total], reduction_to_see)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'clasificado' +'.png', total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación de maleza por sectores\n",
    "* Se basa en la cantidad de vegetación en surco, luego de aplicar operaciones de eliminación de ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T00:26:12.639181Z",
     "start_time": "2020-02-14T00:26:09.805736Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se puede disminuir el costo verificando solo en la parte interna de la máscara de maleza, hace falta conseguir puntos que pertenecen a ella\n",
    "# Con whiles podría quitar varios saltos, comprobaciones y cálculos\n",
    "\n",
    "__furrow_crop_mask = entre_surco_mask.copy()\n",
    "# Itero sobre cada franja\n",
    "for y_index in range(0, len(y_segments) - 1):  # Itera 12 veces, una por segmento\n",
    "    # En cada franja separo en cuadrantes separados por líneas de cultivo (cantidad de líneas + 1)\n",
    "    # En cada cuadrante le sumo la cantidad de vegetación y el tamaño (tamaño tendrá 1 más para no dividir por 0)\n",
    "    weed_amount = np.zeros(len(lines) + 1, np.uint16)\n",
    "    total_pxls = np.ones(len(lines) + 1, np.uint16)\n",
    "    x_by_line = np.zeros(len(lines), np.uint16)\n",
    "    # Obtengo los x de cada línea en la base de la franja, para realizar la separación por cuadrantes\n",
    "    for i in range(0, len(lines)):  # Itera #L veces\n",
    "        x_by_line[i] = lines[i].get_x(y_segments[y_index])\n",
    "    # Itero en la franja correspondiente\n",
    "    # Itera el alto de segmento (máx es 1/12 * (alto de imagen disminuida))\n",
    "    for y in range(y_segments[y_index + 1], y_segments[y_index]):\n",
    "        furrow_index = 0\n",
    "        x = 0\n",
    "        # Itera máx el ancho de la imagen\n",
    "        while ((furrow_index < len(weed_amount)) and (x < crop_mask.shape[1])):\n",
    "            # Me saco todos los 0's del comienzo, si es que tiene\n",
    "            while ((x < crop_mask.shape[1]) and (entre_surco_mask[y, x] == 0)):\n",
    "                x = x + 1\n",
    "            # Colóco el índice donde pertenece\n",
    "            while ((furrow_index < x_by_line.shape[0]) and (x >= x_by_line[furrow_index])):\n",
    "                furrow_index = furrow_index + 1\n",
    "            while ((x < crop_mask.shape[1]) and (entre_surco_mask[y, x] == 255)):\n",
    "                # Procesamiento dentro de surco\n",
    "                total_pxls[furrow_index] = total_pxls[furrow_index] + 1\n",
    "                if _furrow_crop_mask_aperture[y, x] > 10:\n",
    "                    weed_amount[furrow_index] = weed_amount[furrow_index] + 1\n",
    "                x = x + 1\n",
    "            furrow_index = furrow_index + 1\n",
    "    # Adapto la máscara de surco acorde a si cada cuadrante pasa un porcentaje de maleza\n",
    "    weed_porc = 0.10\n",
    "    weed_amount = np.true_divide(weed_amount, total_pxls)\n",
    "    for y in range(y_segments[y_index + 1], y_segments[y_index]):\n",
    "        furrow_index = 0\n",
    "        x = 0\n",
    "        # Itera máx el ancho de la imagen\n",
    "        while ((furrow_index < len(weed_amount)) and (x < crop_mask.shape[1])):\n",
    "            # Me saco todos los 0's del comienzo, si es que tiene\n",
    "            while ((x < crop_mask.shape[1]) and (entre_surco_mask[y, x] == 0)):\n",
    "                x = x + 1\n",
    "            # Colóco el índice donde pertenece\n",
    "            while ((furrow_index < x_by_line.shape[0]) and (x >= x_by_line[furrow_index])):\n",
    "                furrow_index = furrow_index + 1\n",
    "            if (furrow_index >= len(weed_amount)):\n",
    "                print('fuera de rango y: ' + str(y) + ',x: ' +\n",
    "                      str(x) + 'furr ind: ' + str(furrow_index))\n",
    "            _data = 0 if (furrow_index < len(weed_amount)\n",
    "                          and weed_amount[furrow_index] < weed_porc) else 255\n",
    "            while ((x < crop_mask.shape[1]) and (entre_surco_mask[y, x] == 255)):\n",
    "                __furrow_crop_mask[y, x] = _data\n",
    "                x = x + 1\n",
    "            furrow_index = furrow_index + 1\n",
    "#         weed_porc = weed_porc - weed_porc_red\n",
    "\n",
    "# Sectorización de la máscara\n",
    "__furrow_crop_mask_aux = __furrow_crop_mask.copy()\n",
    "for y in y_segments:\n",
    "    cv2.line(__furrow_crop_mask_aux, (0, y),\n",
    "             (morph.shape[1], y), 255, 1)\n",
    "# mostrar_img('furrow', __furrow_crop_mask_aux)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'Sectores' +'.png', __furrow_crop_mask_aux)\n",
    "\n",
    "# Clasificación sectorizada\n",
    "_crop_mask = cv2.resize(crop_mask, None, fx=(\n",
    "    1/rs_ratio), fy=(1/rs_ratio), interpolation=cv2.INTER_AREA)\n",
    "_furrow_crop_mask_aux = cv2.resize(__furrow_crop_mask, None, fx=(\n",
    "    1/rs_ratio), fy=(1/rs_ratio), interpolation=cv2.INTER_AREA)\n",
    "zeros = np.zeros(_crop_mask.shape, np.uint8)\n",
    "mask = cv2.merge((zeros, _crop_mask, _furrow_crop_mask_aux))\n",
    "total = cv2.add(original, mask)\n",
    "mostrar_imgs(['original', 'clasificada'], [original, total], reduction_to_see)\n",
    "# cv2.imwrite(path_to_imgs + file_name + '_'+ 'clasificado_sectores' +'.png', total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "1148.2px",
    "left": "2261px",
    "right": "20px",
    "top": "284px",
    "width": "574.8px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
