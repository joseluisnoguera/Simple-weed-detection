{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se puden mejorar las mascaras haciendolas de un bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from ipynb.fs.full.Utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables de configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_amount = 20 #Cantidad de segmentos\n",
    "window_ratio = 0.05 # 5% con 1024 son ventanas de 51 píxeles (ojo porque quedan pixeles a la derecha si procesar)\n",
    "top_crop_ratio = 0.1\n",
    "width_crop_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_ones_3 = np.ones((3,3),np.uint8)\n",
    "kernel_e1 = np.array(([0,0,0,0],[0,1,1,0],[0,1,1,0],[0,0,0,0]), np.uint8)\n",
    "kernel_e2 = np.array(([0,1,0],[0,1,0],[0,1,0]),np.uint8)\n",
    "kernel_e3 = np.array(([0,0,0],[1,1,1],[0,0,0]),np.uint8)\n",
    "kernel_e4 = np.array(([0,0,0,0,0],[0,1,1,1,0],[0,1,1,1,0],[0,1,1,1,0],[0,0,0,0,0]),np.uint8)\n",
    "kernel_cruz = np.array(([0,1,0],[1,1,1],[0,1,0]),np.uint8)\n",
    "kernel_x = np.array(([1,0,1],[0,1,0],[1,0,1]),np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detección de lineas de cultivo por Hough\n",
    "Detecta una única linea con el contenido de cultivo superior, es donde más se juntan las plantas y hay mayor densidad de puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = take_random_picture('img/row_test_pcam/random/', 'test')\n",
    "to_detect = cv2.cvtColor(original, cv2.COLOR_RGB2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.30006901 17.84511679 18.73248186 ... 18.78150266 18.80273207\n",
      "  19.04844999]\n",
      " [18.15467203 15.74764868 18.72415125 ... 18.77687603 18.79263065\n",
      "  19.04844999]\n",
      " [ 2.40445    18.71071447 18.70918872 ... 18.80650917 18.77849316\n",
      "  19.04844999]\n",
      " ...\n",
      " [18.73709001 18.76718784 18.75004186 ... 18.93866043 19.10001767\n",
      "  19.04844999]\n",
      " [18.73998274 18.76808634 18.78189639 ... 19.35411679 22.23511716\n",
      "  19.04844999]\n",
      " [19.04844999 19.04844999 19.04844999 ... 19.04844999 19.04844999\n",
      "  19.04844999]]\n"
     ]
    }
   ],
   "source": [
    "by_color_index = img_to_color_index(original, 'cive')\n",
    "print(by_color_index)\n",
    "g_to_detect = segment_by_color(to_detect, binary=False)\n",
    "g_to_detect = cv2.erode(g_to_detect, kernel_e1,iterations=1)\n",
    "# mostrar_imgs(['original', 'seg'], [original_td, g_to_detect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bordes por Canny\n",
    "# edges = cv2.Canny(seg_and,50,150)\n",
    "# mostrar_img('edges canny', edges)\n",
    "\n",
    "# Bordes horizontales por convolución (sabiendo que vemos las columnas cultivo de frente)\n",
    "sz_v = 0.4\n",
    "kernel_edge = np.array([[-1,2,-1], #Segmentos verticales\n",
    "           [-1,2,-1],\n",
    "           [-1,2,-1]])\n",
    "edges = cv2.filter2D(g_to_detect,-1,kernel_edge)\n",
    "# edges = cv2.resize(edges, ((int)(edges.shape[1]*sz_v),(int)(edges.shape[0]*sz_v)))\n",
    "mostrar_img('edges conv', edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizando erociones iterativas con kernel vertical\n",
    "g_to_detect_2 = cv2.erode(g_to_detect, kernel_e2,iterations=4)\n",
    "# g_to_detect_3 = cv2.erode(g_to_detect_2, kernel_e3,iterations=1)\n",
    "# mostrar_imgs(['det2', 'det3'], [g_to_detect_2, g_to_detect_3])\n",
    "mostrar_img('edges conv', g_to_detect_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esqueletizar para operar solo con la esqueletización\n",
    "#Se pueden borrar puntos esqueletizados más fácil\n",
    "img_ezq = g_to_detect_2.copy()\n",
    "size = np.size(img_ezq)\n",
    "skel = np.zeros(img_ezq.shape,np.uint8)\n",
    "element = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "done = False\n",
    "while( not done):\n",
    "    eroded = cv2.erode(img_ezq,element)\n",
    "    temp = cv2.dilate(eroded,element)\n",
    "    temp = cv2.subtract(img_ezq,temp)\n",
    "    skel = cv2.bitwise_or(skel,temp)\n",
    "    img_ezq = eroded.copy()\n",
    " \n",
    "    zeros = size - cv2.countNonZero(img_ezq)\n",
    "    if zeros==size:\n",
    "        done = True\n",
    "mostrar_img('skeleton', skel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_lines = original_td.copy()\n",
    "lines = cv2.HoughLines(g_to_detect_2,10,np.pi/90,800)\n",
    "third_1 = (int)(g_to_detect.shape[1]/3)\n",
    "third_2 = (int)(g_to_detect.shape[1]*(2/3))\n",
    "epsilon = (int)(0.01*g_to_detect.shape[1])\n",
    "if type(lines) is np.ndarray:\n",
    "    for line in lines:\n",
    "        for rho,theta in line:\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a*rho\n",
    "            y0 = b*rho\n",
    "            x1 = int(x0 + 2000*(-b))\n",
    "            y1 = int(y0 + 2000*(a))\n",
    "            x2 = int(x0 - 2000*(-b))\n",
    "            y2 = int(y0 - 2000*(a))        \n",
    "            if (x1 != x2 and y2 != y1):\n",
    "                m = (y2-y1)/(x2-x1)\n",
    "                b = y2 - m*x2\n",
    "                x = (g_to_detect.shape[0]-b)/m\n",
    "                if (x > 0 and x < g_to_detect.shape[1]):\n",
    "                    if (x < third_1 and theta < 0.49 and theta > 0.2):\n",
    "                        cv2.line(with_lines,(x1,y1),(x2,y2),(255),1)\n",
    "                    if (x > third_2 and theta > 2.65 and theta < 2.92):\n",
    "                        cv2.line(with_lines,(x1,y1),(x2,y2),(255),1)\n",
    "                    if (x > third_1 and x < third_2 and (theta > 2.75 or theta < 0.39)):\n",
    "                        cv2.line(with_lines,(x1,y1),(x2,y2),(255),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_img('lines', with_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = cv2.subtract(with_lines, g_to_detect)\n",
    "mostrar_img('diferencia', diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagen de prueba para clasificación\n",
    "Se segmenta y se calculan bordes para tener referencia visual (No lo requiere el algoritmo final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'artificial_1'\n",
    "original_td = cv2.imread(img_path + file_name + '.png', cv2.IMREAD_COLOR)\n",
    "# original_td = h_crop(original_td, 0.1) #Para que queden de igual ancho\n",
    "to_detect = cv2.cvtColor(original_td, cv2.COLOR_RGB2HSV)\n",
    "to_detect = v_crop_top(segment_by_color(to_detect), top_crop_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3), np.uint8) \n",
    "to_detect = cv2.erode(to_detect, kernel, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar_img('to_detect', to_detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_detect_edge = cv2.Canny(to_detect,50,150)\n",
    "zeros = np.zeros(to_detect.shape, np.uint8)\n",
    "three_channel_edge = cv2.merge((to_detect, zeros, zeros))\n",
    "mostrar_img('edges canny', three_channel_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación (FIP + RCRD)\n",
    "Trabajo en segmentos, divide la imagen en 20 segmentos (se puede optar por análizar solo la parte inferior, los primeros 15 segmentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_h, td_w = to_detect.shape\n",
    "seg_height = (int)(td_h/segments_amount)\n",
    "steps = (int)(td_h/seg_height) #Si td_h no es múltiplo de la cantidad de seg => steps != segments_amount\n",
    "window_width = (int)(td_w*window_ratio)\n",
    "\n",
    "#RCRD descripto como vectores para que sea más rápido verificar\n",
    "offset_seg_height = 0\n",
    "rcrd_vectors = np.zeros((steps, td_w), np.bool)\n",
    "for i in range(0,steps):\n",
    "    segment = seg_and[offset_seg_height:offset_seg_height + seg_height, 0:td_w]\n",
    "    rcrd_vectors[i,:] = calculate_row(segment, seg_height, td_w)\n",
    "    offset_seg_height = offset_seg_height + seg_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_crop(window):\n",
    "    return True\n",
    "    sum = 0\n",
    "    for elem in window:\n",
    "        if elem:\n",
    "            sum = sum + 1\n",
    "    sz = np.size(window)\n",
    "    return ((sum/sz) > 0.80)\n",
    "        \n",
    "def verificate_with_rcrd(seg_index, window_pos, window_width):\n",
    "#     return True\n",
    "    return np.any(rcrd_vectors[seg_index, window_pos:window_pos + window_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIP\n",
    "offset_seg_height = 0\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# x = np.arange(0,td_w) \n",
    "three_ch_copy = three_channel_edge.copy()\n",
    "\n",
    "#La imagen la voy recorriendo de abajo hacia arriba\n",
    "for seg_index in range(0, steps):\n",
    "    #Calculo los vectores de cada segmento\n",
    "    segment = to_detect[offset_seg_height:offset_seg_height + seg_height,0:td_w]\n",
    "    vector = calculate_row(segment, seg_height, td_w)\n",
    "    \n",
    "    #Todo lo que no sea crop, es weed\n",
    "    window_pos = 0;\n",
    "    while (window_pos < td_w - window_width ):\n",
    "        #Hay algo mal en el algoritmo\n",
    "        if (is_crop(vector[window_pos:window_pos + window_width])):\n",
    "            if (verificate_with_rcrd(seg_index, window_pos, window_width)):\n",
    "            #Luego de verificar que sea crop, pinto ese sector\n",
    "                sector = three_ch_copy[offset_seg_height:offset_seg_height + seg_height, window_pos: window_pos + window_width]\n",
    "                sec_b, sec_g, sec_r = cv2.split(sector)\n",
    "                sector = cv2.merge((sec_r, sec_g, sec_b)) #Lo pinto dando vuelta los canales\n",
    "                three_ch_copy[offset_seg_height:offset_seg_height + seg_height, window_pos: window_pos + window_width] = sector\n",
    "                window_pos = window_pos + window_width\n",
    "            else:\n",
    "                window_pos = window_pos + 1\n",
    "        else:\n",
    "            window_pos = window_pos + 1\n",
    "    offset_seg_height = offset_seg_height + seg_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_img('th', three_ch_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contagio de color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De manera recursiva repinta lo que encuentre a su alrededor\n",
    "def paint(pixel):\n",
    "    if (pixel[0]):\n",
    "        aux = pixel[0]\n",
    "        pixel [0] = pixel[2]\n",
    "        pixel[2] = aux\n",
    "\n",
    "def contagio(img, y_init, x_init):\n",
    "    img_h, img_w, ch = img.shape\n",
    "    x1= x_init-1\n",
    "    x2= x_init+1\n",
    "    y1= y_init-1\n",
    "    y2= y_init+1\n",
    "    if (x1 >= 0): paint(img[y_init,x1])\n",
    "    if (x2 < img_w): paint(img[y_init,x2])\n",
    "    if (y1 >= 0): paint(img[y1,x_init])\n",
    "    if (y2 < img_h): paint(img[y2,x_init])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_ch_copy2 = three_ch_copy.copy()\n",
    "for y in range(0,td_h-1):\n",
    "    for x in range(0,td_w-1):\n",
    "        if (three_ch_copy2[y,x,2]): contagio(three_ch_copy2, y, x) #BGR, el contagio es con R\n",
    "mostrar_imgs(['th contagio','th'], [three_ch_copy2, three_ch_copy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colorearlo en imagen de bordes (Poner valor 255 en segundo (crop) o tercer canal (weed)) \n",
    "#Sumar bordes clasificados con imagen \n",
    "result = cv2.add(original_td, three_ch_copy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_img('resultado', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar resultado\n",
    "file_name='total'\n",
    "cv2.imwrite('img/row_test/' + file_name + '_resultado2.png', result)\n",
    "# cv2.imwrite('img/row_test/' + file_name + '_with_lines.png', with_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
